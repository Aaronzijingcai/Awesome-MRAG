INFO 09-10 10:19:59 [__init__.py:235] Automatically detected platform cuda.
INFO 09-10 10:20:01 [api_server.py:1755] vLLM API server version 0.10.0
INFO 09-10 10:20:01 [cli_args.py:261] non-default args: {'host': '0.0.0.0', 'port': 8888, 'model': '/NAS/caizj/models/deepseek/DeepSeek-R1-Distill-Qwen-1.5B/'}
INFO 09-10 10:20:07 [config.py:1604] Using max model len 131072
INFO 09-10 10:20:08 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 09-10 10:20:12 [__init__.py:235] Automatically detected platform cuda.
INFO 09-10 10:20:14 [core.py:572] Waiting for init message from front-end.
INFO 09-10 10:20:14 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='/NAS/caizj/models/deepseek/DeepSeek-R1-Distill-Qwen-1.5B/', speculative_config=None, tokenizer='/NAS/caizj/models/deepseek/DeepSeek-R1-Distill-Qwen-1.5B/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/NAS/caizj/models/deepseek/DeepSeek-R1-Distill-Qwen-1.5B/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":512,"local_cache_dir":null}
INFO 09-10 10:20:16 [parallel_state.py:1102] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
WARNING 09-10 10:20:16 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 09-10 10:20:16 [gpu_model_runner.py:1843] Starting to load model /NAS/caizj/models/deepseek/DeepSeek-R1-Distill-Qwen-1.5B/...
INFO 09-10 10:20:16 [gpu_model_runner.py:1875] Loading model from scratch...
INFO 09-10 10:20:16 [cuda.py:290] Using Flash Attention backend on V1 engine.
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.75it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.75it/s]

INFO 09-10 10:20:17 [default_loader.py:262] Loading weights took 0.73 seconds
INFO 09-10 10:20:17 [gpu_model_runner.py:1892] Model loading took 3.3466 GiB and 0.852506 seconds
INFO 09-10 10:20:23 [backends.py:530] Using cache directory: /home/caizj/.cache/vllm/torch_compile_cache/27930d4337/rank_0_0/backbone for vLLM's torch.compile
INFO 09-10 10:20:23 [backends.py:541] Dynamo bytecode transform time: 5.73 s
INFO 09-10 10:20:27 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 3.591 s
INFO 09-10 10:20:27 [monitor.py:34] torch.compile takes 5.73 s in total
INFO 09-10 10:20:28 [gpu_worker.py:255] Available KV cache memory: 16.56 GiB
INFO 09-10 10:20:28 [kv_cache_utils.py:833] GPU KV cache size: 620,192 tokens
INFO 09-10 10:20:28 [kv_cache_utils.py:837] Maximum concurrency for 131,072 tokens per request: 4.73x
Capturing CUDA graph shapes:   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graph shapes:   4%|▍         | 3/67 [00:00<00:02, 27.80it/s]Capturing CUDA graph shapes:   9%|▉         | 6/67 [00:00<00:02, 28.26it/s]Capturing CUDA graph shapes:  13%|█▎        | 9/67 [00:00<00:02, 27.13it/s]Capturing CUDA graph shapes:  18%|█▊        | 12/67 [00:00<00:02, 27.02it/s]Capturing CUDA graph shapes:  22%|██▏       | 15/67 [00:00<00:01, 26.69it/s]Capturing CUDA graph shapes:  27%|██▋       | 18/67 [00:00<00:01, 27.69it/s]Capturing CUDA graph shapes:  33%|███▎      | 22/67 [00:00<00:01, 29.21it/s]Capturing CUDA graph shapes:  39%|███▉      | 26/67 [00:00<00:01, 30.18it/s]Capturing CUDA graph shapes:  45%|████▍     | 30/67 [00:01<00:01, 30.67it/s]Capturing CUDA graph shapes:  51%|█████     | 34/67 [00:01<00:01, 31.50it/s]Capturing CUDA graph shapes:  57%|█████▋    | 38/67 [00:01<00:00, 32.49it/s]Capturing CUDA graph shapes:  63%|██████▎   | 42/67 [00:01<00:00, 33.59it/s]Capturing CUDA graph shapes:  69%|██████▊   | 46/67 [00:01<00:00, 35.22it/s]Capturing CUDA graph shapes:  76%|███████▌  | 51/67 [00:01<00:00, 37.67it/s]Capturing CUDA graph shapes:  84%|████████▎ | 56/67 [00:01<00:00, 39.67it/s]Capturing CUDA graph shapes:  91%|█████████ | 61/67 [00:01<00:00, 40.07it/s]Capturing CUDA graph shapes:  99%|█████████▊| 66/67 [00:01<00:00, 41.82it/s]Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:01<00:00, 33.96it/s]
INFO 09-10 10:20:31 [gpu_model_runner.py:2485] Graph capturing finished in 2 secs, took 0.46 GiB
INFO 09-10 10:20:31 [core.py:193] init engine (profile, create kv cache, warmup model) took 13.58 seconds
INFO 09-10 10:20:31 [loggers.py:141] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 38762
WARNING 09-10 10:20:31 [config.py:1528] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 09-10 10:20:31 [serving_responses.py:89] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.95}
INFO 09-10 10:20:31 [serving_chat.py:122] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.95}
INFO 09-10 10:20:31 [serving_completion.py:77] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.95}
INFO 09-10 10:20:31 [api_server.py:1818] Starting vLLM API server 0 on http://0.0.0.0:8888
INFO 09-10 10:20:31 [launcher.py:29] Available routes are:
INFO 09-10 10:20:31 [launcher.py:37] Route: /openapi.json, Methods: HEAD, GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /docs, Methods: HEAD, GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /redoc, Methods: HEAD, GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /health, Methods: GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /load, Methods: GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /ping, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /ping, Methods: GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /tokenize, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /detokenize, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/models, Methods: GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /version, Methods: GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/responses, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/responses/{response_id}, Methods: GET
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/responses/{response_id}/cancel, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/chat/completions, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/completions, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/embeddings, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /pooling, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /classify, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /score, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/score, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/audio/transcriptions, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/audio/translations, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /rerank, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v1/rerank, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /v2/rerank, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /scale_elastic_ep, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /is_scaling_elastic_ep, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /invocations, Methods: POST
INFO 09-10 10:20:31 [launcher.py:37] Route: /metrics, Methods: GET
INFO:     Started server process [1204700]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO 09-10 22:50:56 [chat_utils.py:473] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
INFO 09-10 22:50:56 [logger.py:41] Received request chatcmpl-bcff1b3b453f4da198097891c4673202: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: 设备出现故障该如何解决？ \nContext: [174] Yu Zhao, Huifeng Yin, Bo Zeng, Hao Wang, Tianqi Shi, Chenyang Lyu, Longyue Wang, Weihua Luo,\nand Kaifu Zhang. Marco-o1: Towards open reasoning models for open-ended solutions, 2024. URL\nhttps://arxiv.org/abs/2411.14405.\n67\n\nChen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\n[448] Lei Chen, Xuanle Zhao, Zhixiong Zeng, Jing Huang, Liming Zheng, Yufeng Zhong, and Lin Ma.\nBreaking the sft plateau: Multimodal structured reinforcement learning for chart-to-code generation.\narXiv preprint arXiv:2508.13587, 2025. URLhttps://arxiv.org/abs/2508.13587.\n90\n\n2025. URLhttps://arxiv.org/abs/2505.21668.\n[289] Jie Wu, Haoling Li, Xin Zhang, Jianwen Luo, Yangyu Huang, Ruihang Chu, Yujiu Yang, and Scarlett\nLi. Iterpref: Focal preference learning for code generation via iterative debugging, 2025. URL\nhttps://arxiv.org/abs/2503.02783.\n[290] Nan Jiang, Xiaopeng Li, Shiqi Wang, Qiang Zhou, Soneya Binta Hossain, Baishakhi Ray, Varun\nKumar, Xiaofei Ma, and Anoop Deoras. Ledex: Training llms to better self-debug and explain code.\nIn A. Globerson, L. Mackey, D. Belgrave, A. Fan, U. Paquet, J. Tomczak, and C. Zhang, editors,\nAdvances in Neural Information Processing Systems, volume 37, pages 35517–35543. Curran Associates,\nInc., 2024. URL https://proceedings.neurips.cc/paper_files/paper/2024/file/\n3ea832724870c700f0a03c665572e2a9-Paper-Conference.pdf.\n[291] Zhihui Xie, Jie chen, Liyu Chen, Weichao Mao, Jingjing Xu, and Lingpeng Kong. Teaching language\nmodels to critique via reinforcement learning. InForty-second International Conference on Machine\n\nstrategic flexibility to adapt to novel scenarios or recover from unforeseen errors, a limitation that RL-centric\napproaches directly address by shifting the learning objective from imitation to outcome-driven optimization.\nTool-integrated RL. Building on the limitations of purely imitative paradigms, RL-based approaches\nfor tool use shift the objective from replicating fixed patterns to optimizing end-task performance. This\ntransition enables agents tostrategically decide when, how, andin what combinationto invoke tools, adapting\ndynamically to novel contexts and unforeseen failures. At the foundation, frameworks such as ToolRL [83]\ndemonstrate that, even when initialized from base models without any imitation traces, RL training can\nelicit emergent capabilities, e.g., self-correction of faulty code, adaptive adjustment of invocation frequency,\nand the composition of multiple tools for complex sub-tasks. Subsequently, a recent surge in research \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130123, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 22:50:56 [async_llm.py:269] Added request chatcmpl-bcff1b3b453f4da198097891c4673202.
INFO:     127.0.0.1:51732 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 22:51:03 [loggers.py:122] Engine 000: Avg prompt throughput: 94.9 tokens/s, Avg generation throughput: 34.7 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 09-10 22:51:13 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 09-10 22:52:45 [logger.py:41] Received request chatcmpl-d27c5cc2fa004baeb568f70bddb7a714: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 22:52:45 [async_llm.py:269] Added request chatcmpl-d27c5cc2fa004baeb568f70bddb7a714.
INFO:     127.0.0.1:39540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 22:52:53 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 25.9 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 2.7%
INFO 09-10 22:53:03 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 2.7%
INFO 09-10 22:57:19 [logger.py:41] Received request chatcmpl-24e000bb2b044f968aa0951ea8e1b046: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 22:57:19 [async_llm.py:269] Added request chatcmpl-24e000bb2b044f968aa0951ea8e1b046.
INFO 09-10 22:57:23 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 65.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.3%, Prefix cache hit rate: 38.8%
INFO:     127.0.0.1:42998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 22:57:33 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 38.8%
INFO 09-10 22:57:43 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 38.8%
INFO 09-10 23:03:37 [logger.py:41] Received request chatcmpl-115d7e553124497e8ff881e68fa9da14: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 23:03:37 [async_llm.py:269] Added request chatcmpl-115d7e553124497e8ff881e68fa9da14.
INFO:     127.0.0.1:46932 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 23:03:43 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 26.7 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 55.2%
INFO 09-10 23:03:53 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 55.2%
INFO 09-10 23:22:47 [logger.py:41] Received request chatcmpl-eb7daf25495b4744a36548678159422d: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 23:22:47 [async_llm.py:269] Added request chatcmpl-eb7daf25495b4744a36548678159422d.
INFO:     127.0.0.1:33560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 23:22:53 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 64.5%
INFO 09-10 23:23:03 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 64.5%
INFO 09-10 23:26:21 [logger.py:41] Received request chatcmpl-56ffd8b332e54aa49b2c8233721c9d51: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 23:26:21 [async_llm.py:269] Added request chatcmpl-56ffd8b332e54aa49b2c8233721c9d51.
INFO 09-10 23:26:23 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 39.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.3%, Prefix cache hit rate: 70.6%
INFO:     127.0.0.1:60182 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 23:26:33 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.2 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 70.6%
INFO 09-10 23:26:43 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 70.6%
INFO 09-10 23:28:12 [logger.py:41] Received request chatcmpl-335ede03e54f43daaef75d28d4a605a2: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 23:28:12 [async_llm.py:269] Added request chatcmpl-335ede03e54f43daaef75d28d4a605a2.
INFO 09-10 23:28:13 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 25.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.3%, Prefix cache hit rate: 74.8%
INFO:     127.0.0.1:60608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 23:28:23 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.8 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.8%
INFO 09-10 23:28:33 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.8%
INFO 09-10 23:33:44 [logger.py:41] Received request chatcmpl-4dc6792cff9842148d3b006b8e542a5e: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 23:33:44 [async_llm.py:269] Added request chatcmpl-4dc6792cff9842148d3b006b8e542a5e.
INFO:     127.0.0.1:36288 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 23:33:53 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 49.9 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 78.0%
INFO 09-10 23:34:03 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 78.0%
INFO 09-10 23:35:30 [logger.py:41] Received request chatcmpl-e8b28698c5d941c8b51ee683edee7767: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 23:35:30 [async_llm.py:269] Added request chatcmpl-e8b28698c5d941c8b51ee683edee7767.
INFO:     127.0.0.1:53954 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 23:35:33 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 32.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 80.4%
INFO 09-10 23:35:43 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 80.4%
INFO 09-10 23:37:17 [logger.py:41] Received request chatcmpl-9f6949a9e53b436fb783ff14c670ffe4: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 23:37:17 [async_llm.py:269] Added request chatcmpl-9f6949a9e53b436fb783ff14c670ffe4.
INFO:     127.0.0.1:52128 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 23:37:23 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 82.3%
INFO 09-10 23:37:33 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 82.3%
INFO 09-10 23:42:36 [logger.py:41] Received request chatcmpl-e4d219a60e144841b0b00f859e4f9a2a: prompt: "<｜begin▁of▁sentence｜><｜User｜>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: Instruct: Given a search query, retrieve relevant passages that answer the query\nQuery: Agent的定义是什么？ \nContext: Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming\nLiu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, and\nMaosong Sun. Agentcpm-gui: Building mobile-use agents with reinforcement fine-tuning, 2025. URL\nhttps://arxiv.org/abs/2506.01391.\n82\n\nbenchmark for browsing agents, 2025. URLhttps://arxiv.org/abs/2504.12516.\n[267] Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, and Ge Li. A survey on code\ngeneration with llm-based agents, 2025. URLhttps://arxiv.org/abs/2508.00083.\n[268] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao\nZhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao,\nChenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for a multi-agent collaborative\nframework. InThe Twelfth International Conference on Learning Representations, 2024. URLhttps:\n//openreview.net/forum?id=VtmBAGCN7o.\n[269] Significant Gravitas. AutoGPT: Autonomous gpt-4 agent framework. GitHub, MIT License, 3 2023.\nURL https://github.com/Significant-Gravitas/AutoGPT. Initial release date.\n[270] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi\n\nInfiGUI\nAgent\nUI-\nAGILE\nLeanabell-\nPro ver\nDeepSeek-\nPro ver-v2\nLeanabell-\nPro ver-v2\nSTP\nLeanPr ogress\nKim ina-\nPro ver\nInte rnLM 2. 5-\nSte pProve r\nLean-\nSTaR\nInFiGUI-R1\nAgentCPM\nUI-R1\nZeroGUI\nWebAgent-R1 UI-Venus\nDiGiRL\nUI-TARS\nMaAS\nMAPoRL\nMALT\nReMA\nLERO\nMARFT\nMMedAgent-RL MLPO\nFlow\nReasoner\nTime-R1\nG-Desig\n-ner\nGPT\nSwarm\nTimeMaster\nL-Zero\nAgent\nMod els\nARIA\nGiGPO\nSPA-RL\nTrinity-\nRFT\nSotopia\nRL\nAMPO\nSKyRL\nSQL\nWeak4\nStro ng\nAgent\nPrune\nAgent\nDr opou t\nSirius\nSirius\nACC-\nCollab\nThe Evolution Tree of RL for \nDomain-specific Agents\nMinimo\nPro ofN et++\nCh ain-of-\nA gen ts\nASearc her\nAtom-Sear cher\nMiro Mind\nOS-R1 Re:Form\nMSRL\nSeed-\nProver\nrStar2-\nAgen t\nComputerRL\nMAGRPO\nRL CC F\nFigure 6: The evolution tree of RL for domain-specific agents.\n4.1. Search & Research Agent\nSearch has been central to extending LLMs with external knowledge, with Retrieval-Augmented Generation\n(RAG) as a widely used approach [244, 245]. The paradigm is now evolving beyond simple information\n\nand Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large\nlanguage models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 9354–9366, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.557. URL\nhttps://aclanthology.org/2024.findings-acl.557/.\n[81] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,\nand Sujian Li. Agentbank: Towards generalized llm agents via fine-tuning on 50000+ interaction\ntrajectories. InEMNLP (Findings), pages 2124–2141, 2024. URLhttps://aclanthology.org/\n2024.findings-emnlp.116.\n[82] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,\nand Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. InEMNLP, pages\n3102–3116, 2023. URLhttps://doi.org/10.18653/v1/2023.emnlp-main.187.\n\nKeywords: Agentic Reinforcement Learning, Large Language Models, LLM Agent\nDate: September 1st, 2025\nCode Repository: https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\nCorresponding: jeremyyin@robots.ox.ac.uk, bailei@pjlab.org.cn\nMain Contact: guibinz@u.nus.edu, genghejia0530@gmail.com, x.yu21@imperial.ac.uk\n1\narXiv:2509.02547v1  [cs.AI]  2 Sep 2025 \nAnswer:<｜Assistant｜><think>\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.8, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129648, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
INFO 09-10 23:42:36 [async_llm.py:269] Added request chatcmpl-e4d219a60e144841b0b00f859e4f9a2a.
INFO:     127.0.0.1:44718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 09-10 23:42:43 [loggers.py:122] Engine 000: Avg prompt throughput: 142.4 tokens/s, Avg generation throughput: 37.4 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 83.9%
INFO 09-10 23:42:53 [loggers.py:122] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 83.9%
